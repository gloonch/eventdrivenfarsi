<div dir="rtl">
# EventDrivenFarsi

منبع فارسی برای یادگیری معماری رویداد‌محور و ابزارهای آن به زبان ساده و قابل‌فهم برای انسان‌ها 



# فهرست مطالب

- [معماری Event-Driven چیست؟](#معماری-event-driven-چیست؟)
- [Pub/Sub در یک نگاه](#pubsub-در-یک-نگاه)
- [Apache Kafka برای انسان‌ها](#apache-kafka-برای-انسان‌ها)
  - [Producer و Consumer چیست؟](#producer-و-consumer-چیست؟)
  - [Broker, Topic, Partition](#broker-topic-partition)
  - [Stream Processing چیست؟](#stream-processing-چیست؟)
- [Event Sourcing](#event-sourcing)
- [CQRS](#cqrs)



# معماری Event-Driven چیست؟
در معماری Event-Driven هرگاه چیزی در سیستم اتفاق بیفتد (مثلاً کاربری سفارش جدید ثبت کند، پرداختی موفق شود یا وضعیت دستگاهی تغییر کند) یک event (رویداد) تولید می‌شود. این event به یک event bus یا message broker فرستاده می‌شود و اجزای مختلف سیستم می‌توانند به این event واکنش نشان دهند.

## فروشگاه جادوییِ EventMart
در یک سرزمین خیالی به نام EventLand، فروشگاهی هست به نام EventMart. هرگاه مشتری وارد مغازه می‌شود و کالایی انتخاب می‌کند، صدایی شبیه ping از سقف می‌آید و یک OrderPlaced event ثبت می‌شود.

Publisher (مثل خود مغازه یا یک ماژول ثبت سفارش) این event را روی event bus می‌گذارد.
سپس سه Subscriber آماده‌اند تا واکنش بدهند:
Inventory Service می‌گوید: «باید کالا از انبار بردارم!» و موجودی را کم می‌کند.
Billing Service پیغام OrderPlaced را می‌گیرد و فاکتور می‌سازد.
Notification Service برای مشتری پیامک «سفارش شما ثبت شد» را ارسال می‌کند.
هرکدام از این سرویس‌ها بدون اینکه همدیگر را صدا بزنند، صرفاً منتظر event می‌مانند و وقتی که رویداد جدید می‌رسد، کارشان را انجام می‌دهند. اگر در جایی خطایی رخ دهد یا سرویس جدیدی بخواهند اضافه کنند، کافی‌ست subscriber جدیدی تعریف کنندبی‌هیچ تغییری در Publisher یا سایر اجزا.

مزایای این معماری
Loose Coupling: اجزا مستقل‌اند و فقط از طریق event با هم ارتباط دارند.
Scalability: می‌توان چندین instance از هر سرویس (مثلاً چند Consumer) اجرا کرد تا بار کاری بالاتر را پاسخ دهند.
Extensibility: اضافه کردن قابلیت جدید (مثل سرویس گزارش‌گیری یا analytics) فقط با ثبت یک subscriber جدید ممکن است.

![images/kafka/eventmart.png](images/kafka/eventmart.png)
حالا که متن «فروشگاه جادوییِ EventMart» را خوانده‌اید و به این تصویر نگاه می‌کنید، می‌توانید ببینید که:
مغازه (Publisher) زنگ می‌زند و رویداد را به ابر (event bus) می‌فرستد
سه کاراکتر در سمت راست (Subscribers) هر کدام با فلش‌هایی که از ابر می‌آیند، پیام را دریافت و واکنش نشان می‌دهند
این ارتباط بصری متن و تصویر کمک می‌کند تا نقش Publisher و Subscribers در معماری Event-Driven برایتان کاملاً روشن شود.



## Pub/Sub در یک نگاه

در پهنه‌ی ریل‌های گسترده‌ی ایستگاه مرکزی (Central Station)، هرگاه «ناشر» (Publisher) می‌خواهد پیغامی ارسال کند، یک واگن پر از بسته‌های پیام(یا همان message) را روی ریل می‌چیند. اما این واگن به‌جای آنکه مستقیم به مقصد مشخصی برود، اول باید در Topic Platform نگه داشته شود.

Sir Publisher با عصای فرمانش، واگن‌ها را یکی‌یکی به سکوی Topic می‌فرستد:

Sir Publisher: «واگن حاوی پیام جدید آماده استآن را در سکوی OrderEvents پارک کنید!»
این سکوی Topic مثل یک مخزن موقت است که واگن‌های پیام را نگه می‌دارد تا «مشترک‌ها» (Subscribers) بیایند و بارشان را بردارند.

در سمت دیگر سکو، چند Sir Subscriber در انتظارند:

Knight Inventory برای «اعتبارسنجی موجودی»
Knight Billing برای «صدور فاکتور»
Knight Notification برای «ارسال خبر به مشتری»
هرکدام از این شوالیه‌ها یک قطار ویژه(یا همان Subscription)دارند. وقتی Sir Publisher واگن‌ها را در سکوی Topic رها می‌کند، هر شوالیه به نوبت واگن‌ها را بررسی می‌کند:

Knight Inventory واگن اول را برمی‌دارد، پردازش می‌کند و با ارسال یک ack به Broker می‌گوید «پیام پردازش شد، می‌توانید آزادش کنید.»
سپس Knight Billing واگن بعدی را سوار می‌کند و …
و در نهایت Knight Notification پیغام را تحویل مشتری می‌دهد.
هر Subscriber مستقل کار می‌کند و هیچ‌کدام نیازی به صحبت مستقیم با Sir Publisher ندارند همه چیز از طریق سکوی Topic انجام می‌شود. اگر شوالیه‌ای دیر برسد یا موقتا غایب باشد، واگن‌ها همچنان در سکوی Topic منتظر می‌مانند تا او برگردد.

این است راز Pub/Sub:

Publish = پارک واگن پیام روی Topic
Subscribe = سوارکردن واگن و دریافت پیام
Decoupling = بدون نیاز به تماس مستقیم بین Publisher و Subscriber
Scalability = می‌توانید هر تعداد «قطار مشترک» (Subscription) اضافه کنید تا بار کاری سبک‌تر شود
و این‌گونه است که در ایستگاه Pub/Sub، پیام‌ها به نرمی و بدون تداخل میان ریل‌های Topic و قطارهای Subscriber جابه‌جا می‌شوند بی‌هیچ گره یا تصادفی!



## Apache Kafka برای انسان‌ها

در دنیای قطارهای داده، Apache Kafka مثل یک ایستگاه مرکزی بزرگ است که واگن‌های اطلاعات (پیام‌ها) را از مبدا می‌گیرد و به مقصدهای مختلف می‌فرستد. بیایید هر عنصر اصلی را با حال و هوای راه‌آهن مرور کنیم:


- Broker
تصور کنید چندین ایستگاه کوچک (Broker) در امتداد یک خط آهن بزرگ قرار دارند. هر ایستگاه مسئول ذخیره و عبور واگن‌های اطلاعاتی است. وقتی قطاری وارد ایستگاه می‌شود، واگن‌ها را روی ریل‌های مخصوص پارک (نگهداری) می‌کند تا بعداً راهی ایستگاه بعدی شوند.

- Topic
هر خط آهن در ایستگاه با یک نام مشخص شناخته می‌شود: این نام همان Topic است. مثلاً خط «orders» مختص واگن‌هایی است که شامل سفارش‌های مشتری‌اند.

- Partition
برای اینکه ازدحام قطارها کمتر شود و سرعت بالاتر برود، هر خطوط (Topic) به چند مسیر موازی تقسیم می‌شونداین مسیرها Partition نام دارند. بدین ترتیب چند قطار می‌توانند همزمان روی مسیرهای مختلف حرکت کنند و سرعت انتقال افزایش می‌یابد. 

- Producer
شبیه یک قطار باری است که از کارخانه (اپلیکیشن تولیدکننده) بار می‌گیرد و به ایستگاه مرکزی Kafka می‌آورد. با تنظیم پارامترهایی مثل batch.size و linger.ms، تصمیم می‌گیرد هر چند واگن را یک‌جا سوار کند یا با چه تأخیری حرکت نماید.

- Consumer
در طرف دیگر، قطاری دیگر (یا چند قطار) منتظر است تا از مسیرهای مختلف (Partitionها) عبور کند و واگن‌ها را تخلیه کند. هر Consumer می‌تواند سرعت و طول مسیر (offset) خود را مدیریت کند تا از دریافت دوباره یا از دست دادن پیام جلوگیری شود.

- Stream Processing چیست؟
پس از رسیدن واگن‌ها به ایستگاه مقصد، گاهی لازم است قبل از تخلیه، بارها را مرتب و دسته‌بندی کنیم. این کار مثل Stream Processing است:

قطار (Stream) وارد محوطه‌ی کار (Processing Engine) می‌شود.
واگن‌ها (رویدادها) یک‌به‌یک بررسی، فیلتر یا تبدیل می‌شوند (مثلاً جمع‌آوری آمار یا فشرده‌سازی).
دوباره سوار قطار می‌شوند و به Topic خروجی یا ایستگاه دیگری هدایت می‌شوند.



# Producer و Consumer چیست؟
****در دل دیار فناوری، «ایستگاه کافکا» قرار دارد؛ شبکه‌ای پیچیده از ریل‌ها و سکوها که محموله‌های اطلاعات را جابه‌جا می‌کند. امروز قصه‌ی «سِر پرودیوسر» (Sir Producer)، مأمور ارسال داده‌ها، و همراهانش را بشنوید.

سِر پروڈیوسر (Station Master Producer) با عصای فرمان خود به سکوی بارگیری یا به زبان خودش، buffer نگاهی انداخت:
Sir Producer: «همه‌چیز آماده است؟ باید ۱۰۰ واگنِ اطلاعاتی به قطار بسته شود.»
در کنار سکو، دستیار وفادارش، Lady BatchSize، مشغول تقسیم واگن‌ها به گروه‌های مناسب برای حرکت بود.

Lady BatchSize: «فهرست واگن‌ها آماده است، ولی اگر همه را یک‌جا بفرستیم، حافظه‌ی buffer.memory پر می‌شود.»
Sir Producer لبخندی زد:
«خِرَد می‌گوید بهتر است صبر کنیم تا واگن‌ها جور شوند مثل همین linger.ms اما تنها یک میلی‌ثانیه. این تأخیر اندک هزینه‌ی اندکی latency دارد، اما تعداد درخواست‌ها را کم می‌کند.»
لحظاتی بعد، صدای کوبیدن پتک آهنگر یا همان background I/O thread به گوش رسید؛ صدایی که خبر از آغاز حرکت قطار می‌داد.

Ironhammer (I/O Thread): «همه‌چیز بارگیری شد، آماده ارسال.»
قطار با صدای سوت از «buffer pool» گذشت و به ایستگاه مرکزی یا همان Broker Castle رسید. درون قلعه‌ی Broker، نگهبانان سخت‌گیر وظیفه داشتند هر محموله را بررسی (یا به عبارتی acknowledge) کنند. اگر acks=all باشد، باید همه‌‌ی نگهبانان مهر تأیید بزنند تا قطار اجازه‌ی عبور یابد.

Sir Producer نگران بود:

«اگر یکی از نگهبانان تأخیر کند، قطار متوقف می‌شود. اما با retries=0، اگر خطا رخ دهد، باید قطار را پس بفرستیم و دوباره بارگیری کنیم.»
درون قلعه، Keeper Idempotence همواره مواظب بود تا هیچ بار تکراری وارد نشود؛ همان قابلیتی که وقتی enable.idempotence=true است، از duplicates جلوگیری می‌کند.

همزمان، در سوی دیگر ریل‌ها، «شوالیه‌های Consumer» (Knight Consumers) بی‌تابانه منتظر دریافت محموله‌ها بودند.

Sir Consumer: «ای Broker Castle، برایم مقداری بسته بفرست!»
Broker Castle: «یک لحظه صبر کن؛ درخواست fetch تو در صف است.»
وقتی واگن‌ها آماده می‌شدند، قطار دیگری با نام Fetch Train از سوی Sir Consumer حرکت می‌کرد. اینجا، max.block.ms تعیین می‌کرد چقدر طول می‌کشد تا Sir Consumer، در صورت پر بودن buffer, صبر کند قبل از آن‌که TimeoutException بگیرد.

در پایان روز، Sir Producer و Sir Consumer هر دو گرد هم آمدند و زیر نور فانوس‌های ایستگاه کافکا به استقبال ستارگان ریل‌ها نشستند. آن‌ها می‌دانستند با تنظیم درست batch.size، linger.ms، buffer.memory و acks، می‌توانند قطارهای داده را روان و بی‌خطا هدایت کنند تا جایی که راه‌آهن کافکا دیگر یک بلک‌باکس نباشد، بلکه شبکه‌ای شفاف و قدرتمند باشد.****

![/images/kafka/train in the kafka railway.png](/images/kafka/train%20in%20the%20kafka%20railway.png)
این تصویر روایت Producer و Consumer را با تم ایستگاه راه‌آهن نشان می‌دهد:

سمت چپ، واگن‌های «buffer» و «batch size» قرار دارند (کمک می‌کنند پیام‌ها آمادهٔ ارسال شوند).
میانهٔ تصویر، «buffer pool» شبیه یک حوض، بین تولیدکننده‌ها و «Broker Castle» (ایستگاه مرکزی) فاصله می‌اندازد.
سمت راست، قطار «Fetch Train» و شوالیهٔ Consumer آماده‌اند تا بسته‌ها را از ایستگاه (Broker) بگیرند و پردازش کنند.

## Broker, Topic, Partition

در ایستگاه مرکزی Broker Station، هر Topic مثل یک سکوی مشخص (Platform) است و هر Partition آن سکو، مثل یک ریل جداگانه (Track) که بارها (Messages) روی آن حرکت می‌کنند.

Broker = ایستگاه مرکزی

Broker مثل ساختمان اصلی ایستگاه است که مسئول نگهداری ریل‌ها (Partitions) و هماهنگی حرکت قطارها (Producers و Consumers) است.
هرگاه Sir Producer بخواهد واگن جدیدی ارسال کند، ابتدا باید از دربار Broker گذر کند تا واگن به سکوی درست هدایت شود.
Topic = سکوی بارگیری

یک Topic برابر است با یک Platform در ایستگاه. مثلاً سکوی OrderEvents یا سکوی PaymentEvents.
واگن‌های پیام را روی سکوی مربوطه پارک می‌کنند و منتظر می‌مانند که Subscribers بیایند و ببَرند.
Partition = ریل‌های جداگانه

هر سکوی Topic می‌تواند چند Partition داشته باشد، مثل چند ریل موازی زیر یک سکو.
وقتی چند Producer هم‌زمان پیام می‌فرستند، هر پیام روی یکی از ریل‌ها (Partitions) قرار می‌گیرد تا بتوانند همزمان جابه‌جا شوند و از ترافیک جلوگیری شود.
ترتیب واگن‌ها (Ordering) فقط روی همان ریل (Partition) حفظ می‌شود؛ اگر چند واگن پشت‌سر هم روی ریل شماره ۲ قرار بگیرند، Sir Consumer وقتی از ریل ۲ می‌گیرد، دقیقاً به همان ترتیب پیام‌ها را می‌خواند.


ماجرا در ایستگاه
Sir Producer از دروازه Broker وارد می‌شود و درخواست می‌دهد: «می‌خواهم پیام جدید روی Topic OrderEvents بگذارم.»
Broker می‌گوید: «خیالت راحت، سکو را باز کردم. Partition 0 و Partition 1 آماده‌اند.»
Sir Producer بسته را روی Partition 1 قرار می‌دهد (rail 1).
هم‌زمان Sir Consumerهای مختلف می‌آیند و هرکدام یکی از ریل‌ها را برای سوارکردن بسته‌ها انتخاب می‌کنند مثلاً یکی از ریل ۰ و دیگری از ریل ۱.
اگر یکی از ریل‌ها شلوغ شد، Broker می‌تواند Producer را به ریل خالی بعدی راهنمایی کند تا ترافیک بهینه بماند.
با این چیدمانِ Broker + Topic + Partitions، ایستگاه کافکا می‌تواند حجم زیادی از پیام‌ها را به‌صورت موازی و منظم مدیریت کند و همزمان تضمین کند که ترتیب پیام‌ها روی هر ریل (Partition) دست‌نخورده باقی بماند.

![/images/kafka-broker-topic-partition.png](/images/kafka/kafka-broker-topic-partition.png)
این تصویر ایستگاه مرکزی (یا همان Broker) را نشان می‌دهد که سکو (Topic) روی یک پلتفرم بزرگ قرار دارد و سه ریل موازی زیر آن (Partitions) برای جابه‌جایی پیام‌ها (واگن‌ها) آماده‌اند. هر ریل مسیر مستقل خود را دارد اما همگی زیر نظر ایستگاه مرکزی اداره می‌شوند تا پیام‌ها به‌صورت موازی و مرتب حرکت کنند.




# Stream Processing
در حیاط بزرگ «کارگاه پردازش» (Processing Yard) ایستگاه کافکا، قطارهای بار (Streams) متوقف می‌شوند تا قبل از رسیدن به مقصد نهایی، واگن‌هایشان مرتب و ارزیابی شوند:

۱. ورود قطار پردازش (Stream Ingestion)
در این مرحله، قطار باری از ریل‌های اختصاصی Partition جدا می‌شود و وارد محوطهٔ کارگاه پردازش می‌گردد. هر Wagon (پیام) به‌طور جداگانه بارگذاری و برای مراحل بعدی آماده می‌شود. معمولاً از ابزارهایی مثل Kafka Connect یا Kafka Streams API استفاده می‌شود تا جریان ورودی را دریافت و به پردازشگرهای بعدی تحویل دهد. این کار تضمین می‌کند که هیچ رویدادی از بین نرود و همهٔ پیام‌ها به ترتیب وارد خط پردازش شوند.

۲. بازرسی و فیلتر (Filter & Inspect)
هر Wagon به‌عنوان یک Event، توسط مجموعه‌ای از قوانین و معیارها (Predicate) بررسی می‌شود. اگر بار داخلی معتبر نباشد (Invalid Event)، از جریان اصلی جدا شده و برای لاگ یا لاگیک تصحیح فرستاده می‌شود. در مقابل، پیام‌هایی که باید تغییر قالب یا غنی‌سازی شوند (Transform)، به سمت مبدل‌های مربوطه هدایت می‌گردند. این مرحله معمولاً با توابع Map/FlatMap یا Processor API پیاده‌سازی می‌شود.

۳. ترکیب و محاسبه (Aggregation & Enrichment)
پس از فیلتر اولیه، رویدادهای مرتبط بر اساس کلید یا تایم‌ویندوی مشخص گروه‌بندی (Windowing) می‌شوند. برای مثال، سفارش‌های یک مشتری در بازهٔ یک دقیقه‌ای کنار هم قرار می‌گیرند و مجموع مبلغ محاسبه می‌شود (Count, Sum, Average). همچنین می‌توان با کوئری به سرویس‌های خارجی، به هر پیام دادهٔ زمینه‌ای (Metadata) اضافه کرد (مثل اطلاعات کاربر یا نرخ ارز). این ترکیب باعث می‌شود خروجی بهینه‌تر و هوشمندانه‌تر باشد.

۴. بارگذاری مجدد روی ریل (Re‑Emission)
واگن‌های پردازش‌شده مجدداً روی Topicهای خروجی (Output Topics) قرار می‌گیرند تا سایر سرویس‌های پایین‌دستی (Downstream) بتوانند آنها را دریافت کنند. این مرحله تضمین می‌کند که نتایج پردازش—مثل گزارش‌های آماری، هشدارها یا داده‌های غنی‌شده—در دسترس سرویس‌های بعدی قرار گیرد. معمولاً با عملیات to() در Kafka Streams یا ارسال پیام از طریق Producer API انجام می‌شود.

۵. نظارت و خطاگیری (Monitoring & Fault Handling)
در طول کار، ابزارهای مانیتورینگ (مثل Prometheus/Grafana) مصرف حافظه، تاخیر پردازش و نرخ خطا را رصد می‌کنند. اگر خطای نرم (مثلاً داده ناقص) رخ دهد، پیام به Dead‑Letter Topic فرستاده شده و پردازش ادامه می‌یابد. در مواجهه با خطای سخت (مثل قطع ارتباط Broker)، مکانیزم‌های بازگشت (Retry) یا جابجایی (Fallback) پیاده‌سازی می‌شود تا جریان کلی مختل نشود. این سازوکارها تضمین می‌کنند که سیستم همیشه پایدار و قابل اطمینان بماند.

![images/kafka/stream processors.png](images/kafka/stream%20processors.png)
این تصویر مثل یک کارگاه راه‌آهن است که واگن‌های پر از رویداد (Events) وارد آن می‌شوند، کارگران (Stream Processors) آنها را فیلتر و مرتب می‌کنند و سپس واگن‌ها را روی ریل‌های خروجی می‌گذارند تا دوباره حرکت کنند

# Event Sourcing




# CQRS
</div>
